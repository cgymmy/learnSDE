\chapter{Random Field}\label{cap5}
Here we discussed about the classical numerical methods and SPDE-based approaches for simulating the random field.
\section{Random Field}
\subsection{Definitions}
\begin{definition}[Random Field]
    For a set $D\subset \mathbb{R}^d$, a (real-valued) random field ${u(x):x\in D}$ is a set of real-valued 
    random variables on a probability space $(\Omega, \mathcal{F}, P)$. We usually speak of realizations of random field, instead of sample paths. 
\end{definition}

\begin{definition}[second-order random field]
    A random field is called second-order random field if $u(x)\in L^2(\Omega)$ for $\forall x\in D$. With its mean and covariance function:
    \begin{equation}\left\{
        \begin{aligned}
            \mu(x) &= \mathbf{E}[u(x)]\\
            C(x, y) &= Cov(u(x), u(y))=\mathbf{E}[(u(x)-m(x))(u(y)-m(y))]\\
        \end{aligned}\right.
    \end{equation}
\end{definition}

\begin{definition}[Gaussian Random Field]
    A second-order random field ${u(x):x\in D}$ is called Gaussian random field if 
    \begin{equation}
        u = u[u(x_1), u(x_2), \cdots, u(x_n)]^T \sim \mathcal{N}(\mu(x), C(x, y)),\ \forall x_i \in D
    \end{equation}
\end{definition}

\begin{example}[$L^2(D)$-valued random variable]
    For $D\subset \mathbb{R}^d$, consider $L^2(D)$-valued R.V. u with $\mu \in L^2(D)$ and $\mathscr{C}$.
    Then $u(x)$ is a real-valued random field for each $x\in D$, and mean and covariance are well defined.

    Meanwhile, for $\phi, \psi \in L^2(D)$, we have
    \begin{equation}
        \begin{aligned}
            \langle \mathscr{C}\phi, \psi \rangle &= Cov\left(\langle u, \phi \rangle_{L^2(D)}, \langle u, \psi \rangle_{L^2(D)}\right)\\
            &=E\left[\left(\int_D \phi(x)(u(x)-\mu(x))dx\right)\left(\int_D \psi(y)(u(y)-\mu(y))dy\right)\right]\\
            &=\int_D \int_D \phi(x)\psi(y)E[(u(x)-mu(x))(u(y)-mu(y))]dxdy\\
            &=\int_D \int_D \phi(x)\psi(y)Cov(u(x), u(y))dxdy\\
        \end{aligned}
    \end{equation}
    So that
    \begin{equation}
        (\mathscr{C}\phi)(x) = \int_D Cov(u(x), u(y))\phi(y)dy
    \end{equation}
    which is the covariance function of the random field $u(x)$. So, any $L^2(D)$-valued random variable defines a second-order random field, 
    with mean $\mu(x)$ and covariance $C(x, y) = Cov(u(x), u(y))$ which is the kernel of the covariance operator $\mathscr{C}$.
\end{example}

\begin{example}[Stationary Random Field]
    A second-order random field ${u(x): x\in D}$ is called stationary if the mean is constant and covariance function 
    depends only on the difference $x-y$, i.e. $\mu(x) = \mu,\ C(x, y) = C(x-y)$.
\end{example}

\begin{theorem}[Wiener-Khinchin Theorem]
    There exists a stationary random field ${u(x): x\in D}$ with mean $\mu$ and covariance function $c(x)$ that is mean square continuous if and only if 
    the function $c(x): \mathbb{R}^d\rightarrow \mathbb{R}$ is such that 
    \begin{equation}
        c(x) = \int_{\mathbb{R}^d} e^{iv \cdot x}dF(v) = (2\pi)^{\frac{d}{2}}\hat{f}(x)
    \end{equation}
    where $F(v)$ is some measure on $\mathbb{R}^d$ and $\hat{f}(x)$ is the Fourier transform of $f(x)$, f is the density function of $F$.
    
    Reversely, $f(v) = (2\pi)^{\frac{d}{2}}\hat{c}(v)$.
    If $f$ is non-negative and integrable, then $c(x)$ is a valid covariance function.
\end{theorem}

\begin{example}[Isotropic Random Field]
    A stationary random field is called isotropic if its covariance function depends only on the distance between points, i.e.
    \begin{equation}
        Cov(x) = c(\|x\|_2) = c^0(r)
    \end{equation}
    where $c^0$ is known as the isotropic covariance function.
\end{example}
\subsection{Algorithms}
In 2D cases, the covariance matrices of samples of stationary random fields $u(x)$ at uniformly spaced points $x\in D$ are symmetric BTTB matrices.
\begin{definition}[Uniformly spaced points]
    Let $D = [0,a_1]\times[0,a_2]$, the uniformly spaced points are given by:
    \begin{equation}
        x_k = x_{i,j} = (i\Delta x_1, j\Delta x_2)^T,\ i = 0, 1, \cdots, n_1-1,\ j = 0, 1, \cdots, n_2-1, k=i+j n_1
    \end{equation}
    where $\Delta x_1 = \frac{a_1}{n_1-1}$ and $\Delta x_2 = \frac{a_2}{n_2-1}$. 
    
    With $N=n_1n_2$, $u = [u_0, u_1, \cdots, u_{N-1}]^T\sim \mathcal{N}(0, C)$ is the vector of samples of $u(x)$ at the uniformly spaced points.
    Since $u(x)$ is stationary, $C$ is a $N\times N$ symmetric BTTB matrix with elements:
    \begin{equation}
        C_{kl} = Cov(u_k, u_l) = c(x_{{i+jn_1}} - x_{r+sn_1})
    \end{equation}
    where $c(x_k - x_l)$ is the covariance function of $u(x)$. 
\end{definition}


\begin{theorem}
    The covariance matrix $C$ is always a symmetric BTTB matrix.
\end{theorem}

Since we have the Fourier representation of BCCB matrix and BTTB matrix can by extended to BCCB by even extension, we can use the following algorithm to generate the samples of $u(x)$.
So, when the even BCCB extension $\tilde{C}\in \mathbb{R}^{4N\times 4N}$ is non-negative definite, then $N(0, \tilde{C})$ is a valid Gaussian distribution.

\begin{algorithm}
    Suppose the even BCCB extension $\tilde{C}\in \mathbb{R}^{4N\times 4N}$ is non-negative definite, and the leading principle submatrix $S\in \mathbb{R}^{2N\times 2N}$ is:
    \begin{equation}
        S = \begin{pmatrix}
            \tilde{C}_0 & \tilde{C}_1^T & \cdots & \tilde{C}_{n_2-1}^T\\
            \tilde{C}_1 & \tilde{C}_2 & \cdots & \tilde{C}_{n_2-2}^T\\
            \vdots & \vdots & \ddots & \vdots\\
            \tilde{C}_{n_2-1} & \tilde{C}_{n_2-2} & \cdots & \tilde{C}_0
        \end{pmatrix},\quad \tilde{C}_i = \begin{pmatrix}
            C_i & B_i\\
            B_i & C_i
        \end{pmatrix}
    \end{equation}
    where $C_i, B_i \in \mathbb{R}^{n_1\times n_1}$, $i = 0, 1, \cdots, n_2-1$. 
    
    Now given $\tilde{u}\sim N(0, \tilde{C})$, let $v$ be the first $2n_1n_2$ elements of $\tilde{u}$, 
    then $v\sim N(0, S)$. Take the first $n_1$ elements of $v$ per $2n_1$ elements to get $\tilde{v}\sim N(0, C)$.
\end{algorithm}

However, when the even BCCB extension $\tilde{C}\in \mathbb{R}^{4N\times 4N}$ is indefinite, we can avoid this by padding. 
But sometimes, padding leads to the size of matrix explosion. Approximate circulant embedding may be the only option.

\subsection{KL expansion of R.F.}
As mentioned before, we have the underlying covariance operator defined by:
\begin{equation}
    (\mathscr{C}\phi)(x) = \int_D Cov(u(x), u(y))\phi(y)dy=\int_D c(x-y)\phi(y)dy
\end{equation}
Hence, for the covariance operator $\mathscr{C}$, we have the eigenfunctions with corresponding eigenvalues $\{v_j, \phi_j\}_{j=1}^{\infty}, v_j\geq v_{j-1}$.
\begin{theorem}[$L^2$ convergence of KL expansion]
    Let $D\subset \mathbb{R}^d$, consider a random field $u(x): x\in D$ and $u\in L^2(\Omega, L^2(D))$, then:
    \begin{equation}
        u(x) = \mu(x) + \sum_{j=0}^{\infty} \sqrt{v_j} \phi_j(x) \xi_j
    \end{equation}
    where the sum converges in $L^2(\Omega, L^2(D))$, 
    \begin{equation}
        \xi_j = \frac{1}{\sqrt{v_j}}\int_D (u(x)-\mu(x))\phi_j(x)dx
    \end{equation}
    The random variables $\xi_j$ have mean zero, unit variance and are pairwise uncorrelated.
    If u is Gaussian, then $\xi_j$ are i.i.d. Gaussian random variables with zero mean and unit variance.
\end{theorem}


\section{For Stationary RF on $\mathbb{R}^d$}
First we define stationary random field on $\mathbb{R}^d$ as:
\begin{definition}[Stationary Random Field]
  A second-order random field ${u(x): x\in D}$ is called stationary if the mean is constant and covariance function 
  depends only on the difference $x-y$, i.e. $\mu(x) = \mu,\ C(x, y) = C(x-y)$.
\end{definition}
Then we can define the covariance operator $\mathcal{C}$ as:
\begin{equation}
  \mathcal{C}\phi = \int_{\mathbb{R}^d} C(x-y)\phi(y)dy
\end{equation}
We find that it is actually the convolution operator of $C(x)$ with $\phi(x)$.

Stationary random fields have some beautiful properties.
\begin{theorem}[Wiener-Khinchin Theorem]
    There exists a stationary random field ${u(x): x\in D}$ with mean $\mu$ and covariance function $c(x)$ that is mean square continuous if and only if 
    the function $c(x): \mathbb{R}^d\rightarrow \mathbb{R}$ is such that 
    \begin{equation}
        c(x) = \frac{1}{(2\pi)^{d}}\int_{\mathbb{R}^d} e^{ik \cdot x}dF(k)=\frac{1}{(2\pi)^{d}}\int_{\mathbb{R}^d} e^{ik \cdot x}S(k)dk = \left(\mathcal{F}^{-1}S\right)(x)
    \end{equation}
    where $F(k)$ is some measure on $\mathbb{R}^d$ called spectral distribution and $\hat{S}(x)$ is the Fourier transform of $S(k)$, 
	called spectral density.
    Reversely, $S(k) = \left(\mathcal{F}c\right)(k) = \hat{c}(k)$.
    If $S(k)$ is non-negative and integrable, then $c(x)$ is a valid covariance function.
\end{theorem}

\begin{theorem}[Spectral Density of Random Field]\label{spectral_density_random_field}
	Assume $u(x)$ has zero mean, then 
\begin{equation}\label{spectraldensity}
	S_u(k)=\frac{1}{(2\pi)^{d}}\mathbb{E}[|\hat{u}(k)|^2]
\end{equation}
\end{theorem}



% \begin{equation}
% 	\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} e^{-ik(x-y)}c(x-y)dxdy
% \end{equation}

By defining the pseudo-differential operators, the class of SPDEs is defined by:
\begin{equation}
	\mathcal{L}_gu = W, \mathcal{L}_g = \mathcal{F}^{-1}g\mathcal{F}
\end{equation}
where $g:\mathbb{R}^d\rightarrow \mathbb{C}$ must be a sufficiently regular and Hermitian-symmetric function, that is it must satisfy: $g(k) = \overline{g(-k)}$, $\overline{\cdot}$ denotes the complex conjugate.
So if we have $\mathcal{L}_gu = W$, then:
\begin{equation}
	u=\mathcal{L}_{\frac{1}{g}}W
\end{equation}

\begin{theorem}
	The spectral density of $\mathcal{L}_gu$ and of $u$ are related by:
	\begin{equation}
		S_{\mathcal{L}_gu}(k) = \left|g(k)\right|^2S_u(k)
	\end{equation}
	Generally, if 
	\begin{equation}\label{SPDEGeRF}
		\mathcal{L}_gu = w
	\end{equation}
	where $w$ is a GeRF source term, then $S_w(k) = \left|g(k)\right|^2S_u(k)$.
	Therefore, when $w = W$, $S_u =\frac{1}{(2\pi)^{d}\left|g(k)\right|^2}\mathbb{E}[|\hat{W}(k)|^2]=\frac{1}{\left|g(k)\right|^2}$. 
  Then, 
\begin{equation}
	u(x) =\mathcal{L}_{\frac{1}{g}}w(x) = \mathcal{L}_{\sqrt{\frac{S_u}{S_w}}}w(x)
\end{equation}
\end{theorem}

Then consider the exitence of the function.
\begin{theorem}
	Let $w(x)$ be a real stationary GeRF over $\mathbb{R}^d$, and let $g:\mathbb{R}^d\rightarrow \mathbb{C}$ be a symbol function. 
	Then for (\ref{SPDEGeRF}), there exists a unique stationary solution $u(x)$ if and only if:
	there exists $N\in \mathbb{N}$ s.t. 
	\begin{equation}
		\int_{\mathbb{R}^d}\frac{dS_w(k)}{\left|g(k)\right|^2(1+\|k\|^2)^N} < \infty
	\end{equation}
	and 
	\begin{equation}
		S_u(k) = \left|g(k)\right|^{-2}S_w(k)
	\end{equation}
	Moreover, $S_u(k)$ is unique if and only if $\left|g\right|>0$.
\end{theorem}

% Inspired by SPDE approach: 
% \begin{theorem}
%     For $\forall u\in U:=L^2(D\times \Omega)$, a stationary random field with covariance function $c(x)$, $\exists L \in \mathcal{L}(U)$ s.t.
% 	$\mathcal{L}u = W$, where $W$ is a spatial Gaussian white noise with unit variance. 
% \end{theorem}

% Hence we can use a DNN-based model as the surrogate operator $\mathcal{N}$ of $L$. Here we use the Fourier transform to encode the solution $u$ to Fourier space: 
% \begin{equation}
%     \mathcal{F}(Lu)(k)=\hat{L}(k)\hat{u}(k) = \hat{W}\Rightarrow u(x) = \mathcal{F}^{-1}\left(\frac{\hat{W}}{\hat{L}}\right)(x)=\mathcal{F}^{-1}\left(\hat{\mathcal{N}}\hat{W}\right)(x)
% \end{equation}
Hence the key is the symbol function $g(k)$.
The following theorem shows that solutions of SPDEs with White Noise source term is the starting point of more general solutions, when the source term can be any stationary GeRF.
\begin{theorem}\label{uniquenessandexistence}
	Let $w(x)$ be a real stationary GeRF over $\mathbb{R}^d$ with covariance distribution $C_w(x)$. 
	Let $g$ be a symbol function over $\mathbb{R}^d$ such that $\frac{1}{g}$ is smooth with polynomially bounded derivatives of all orders. 
	Then, there exists a unique stationary solution to (\ref{SPDEGeRF}) and its covariance distribution is given by
\begin{equation}
	C_u(x) = C_u^W * C_w(x)
\end{equation}
where $C_u^W$ is the covariance function of the solution to the SPDE with White Noise source term.
\end{theorem}
\begin{proof}
	The proof is straightforward by using Wiener-Khinchin theorem.
\end{proof}
For any precision operator which is a polynomial in the Laplacian, $Q = p(-\Delta)$, such as the Matern operator with $\nu \in \mathbb{N}$, 
this results in a polynomial $F(Q) = p(\|k\|^2)$.
\subsection{Matern Field}
The important relationship that we will make use of is that a Gaussian field $u(x)$ with the Matern covariance is 
a solution to the linear fractional stochastic partial differential equation (SPDE):
\begin{equation}\label{SPDE}
	\mathcal{L}^{\alpha/2}u(x) = (\kappa^2 - \Delta)^{\alpha/2} u(x) = W(x), \qquad x\in D\in \mathbb{R}^d, \alpha=\nu + d/2, \kappa>0, \nu>0,
\end{equation}
where $\nu = \alpha - d/2, \rho = \frac{\sqrt{2\nu}}{\kappa}$ is the range parameter, $\Delta$ is the Laplacian operator, $W(x)$ is a spatial Gaussian white noise with unit variance.
We will name any solution to Equ (\ref{SPDE}) a Matern field in the following. 

\begin{theorem}[Spectral Solution of Matern Field]\label{spectral_solution_matern}
	The solution of u solved by Equ (\ref{SPDE}) is given by:
	\begin{equation}
		u(x) = \mathcal{F}^{-1}\left[\frac{\hat{W}(k)}{(\kappa^2 + \|k\|^2)^{\alpha/2}}\right](x)
	\end{equation}
	where $\mathcal{F}$ is defined in (\ref{FourierTransform}).
	And the covariance function of u is given by:
	\begin{equation}
		c(x) = \frac{\sigma^2}{2^{\nu -1}\Gamma(\nu)}(\kappa \|x\|)^\nu K_\nu (\kappa \|x\|)
	\end{equation}
	where $\nu = \alpha - d/2, \rho = \frac{\sqrt{2\nu}}{\kappa}, \sigma^2 = \frac{\Gamma(\nu)}{(4\pi)^{d/2}\kappa^{2\nu}\Gamma(\alpha) }$
\end{theorem}


% By Wiener-Khinchin theorem, we have known that: given a stationary covariance function $c(x)$ 
% that is mean square continuous, we can always have a spectral density $S(k)$. Then the problem comes to:
% if exists an operator $\mathcal{L}$ s.t. 

Wiener-Khinchin theorem + Spectral Theorem.
\subsection{Generalized Matern Field}
Consider the following SPDE:
\begin{equation}\label{GWM}
	(\kappa^2 +(- \Delta)^{\gamma})^{\alpha/2}u(x)=\mathcal{F}^{-1}\left((\kappa^2 + \|k\|^{2\gamma})^{\alpha/2}\mathcal{F}u\right)(x) = W(x), \quad x\in D\in \mathbb{R}^d
\end{equation}
Hence the solution is:
\begin{equation}
	u(x)=\mathcal{F}^{-1}\left[\frac{\hat{W}(k)}{(\kappa^2 + \|k\|^{2\gamma})^{\alpha/2}}\right](x)
\end{equation}
Therefore the spectral density is:
\begin{equation}
	S_u(k)=\frac{1}{(\kappa^2 + \|k\|^{2\gamma})^{\alpha}}
\end{equation}
So when $\gamma = 1$, it becomes the Matern Field. Since  the spectral density $S_u(k)\in L^2(\mathbb{R}^d)$ if and only if $\alpha \gamma > \frac{d}{2}$.

Generally, we can define the pseudo-differential operator through symbol function $g(k)$.
\section{Spatial-Temporal General Random Field on $\mathbb{R}^d\times (0, T)$}
\subsection{Stein Model}
Proposed in \cite{stein2005space}, we define the spatial-temporal white noise $\mathcal{W}(x,t)$ as Gaussian noise that is white in time but correlated in space.
\begin{equation}\label{SteinModel}
	\left(b(s^2-\frac{d}{dt^2})^\beta + a(\kappa^2-\Delta)^\alpha\right)^{\nu / 2}u(x,t) = W,\qquad (x, t)\in D\times (0, T)
\end{equation}
Consider when $D = \mathbb{R}^d$, where the space-time spectral density of the stationary solution is given by:
\begin{equation}
	S_u(k_s, k_t) = \frac{1}{(b(s^2 + k_t^2)^\beta + a(\kappa^2 + k_s^2)^\alpha)^\nu}
\end{equation}
We note the spatio-temporal symbol function as:
\begin{equation}
	g(k_s, k_t): (k_s, k_t)\rightarrow (b(s^2 + k_t^2)^\beta + a(\kappa^2 + k_s^2)^\alpha)^{\nu/2}
\end{equation}
When $\alpha, \beta, \nu$ are positive and $\frac{d}{\alpha\nu}+\frac{1}{\beta\nu} = 2$, 
\cite{stein2005space} shows that the spectral density is finite and the corresponding random field is mean square continuous.

\begin{theorem}
	When $\kappa, s, a, b>0$ and $\alpha, \beta, \nu$ are not null, $g(k_s, k_t)$ satisfies Thm \ref{uniquenessandexistence}, 
then for any stationary GeRF $X$, the SPDE:
\begin{equation}
	\left(b(s^2-\frac{d}{dt^2})^\beta + a(\kappa^2-\Delta)^\alpha\right)^{\nu / 2}U(x,t) = X(x,t)
\end{equation}
has a unique stationary solution $U(x,t)$ with covariance function:
\begin{equation}
	C_U(x, y, t, s) = C_U^W*C^X(x-y, t-s)
\end{equation}
\end{theorem}

\subsection{Evolution Equations Model}
Here we consider the following model:
\begin{equation}
	\frac{\partial^\beta u}{\partial t^\beta} + \mathcal{L}_gu = w(x,t)
\end{equation}
where $\mathcal{L}_g$ is a pseudo-differential operator with symbol $g(k)$ and $w(x,t)$ is a stationary spatio-temporal GeRF.
\begin{equation}
	g(k_s, k_t) = (ik_t)^\beta + g(k_s)
\end{equation}

\subsection{Advection-Diffusion SPDE}
This is poeposed in \cite{sigrist2015stochastic}. The equation is given by:
\begin{equation}
	\left[\frac{\partial}{\partial t} - \nabla \cdot (\Sigma \nabla)+\mu \nabla + C\right]u(x,t) = w(x,t)
\end{equation}
where $\Sigma$ is the diffusion matrix, $\mu$ is the advection velocity, $C$ is the drift coefficient.
Here we set the diffusion matrix as:
\begin{equation}
	\Sigma = \frac{1}{\rho^2}\begin{pmatrix}
		\cos\theta & \sin\theta \\
		-\gamma\sin\theta & \gamma\cos\theta
	\end{pmatrix}^T\begin{pmatrix}
		\cos\theta & \sin\theta \\
		-\gamma\sin\theta & \gamma\cos\theta
	\end{pmatrix}
\end{equation}
where $\rho$ is the correlation length and $\gamma$ is the anisotropy ratio, $\theta\in [0, \pi/2)$. With $\gamma = 1$, it becomes isotropic.
Similarly the spectral density is given by:
\begin{equation}
	\begin{aligned}
		S_u(k_s, k_t) &= \frac{S_w(k_s, k_t)}{\left|i(k_t + \mu k_s) + (C + k_s^T\Sigma k_s)\right|^2}\\
		&= \frac{S_w(k_s, k_t)}{(k_t + \mu k_s)^2 + (C + k_s^T\Sigma k_s)^2}\\
		&= \frac{S_w(k_s, k_t)}{\left|g_u\right|^2}\\
	\end{aligned}
\end{equation}
By Wiener-Khinchin theorem, the covariance function is given by:
\begin{equation}
	C_u(x, t) = \frac{1}{(2\pi)^{d}}\int S_w\frac{e^{-i\mu k_s t-(k_s^T\Sigma k_s + C)|t|}}{2(k_s^T\Sigma k_s + C)}e^{ik_s x}dk_s
\end{equation}
Specifically, when $\mu = 0, \Sigma = 0$, the covariance function is given by:
\begin{equation}
	C_u(x, t) = \frac{e^{-C|t|}}{2C}C_w(x, t)
\end{equation}
However $\mu(x)$ may not be constant.

\subsection{Generic class of non-stationary models}
Similar to ADSPDE, we consider:
\begin{equation}
	\frac{\partial u}{\partial t} + \left[ - \nabla \cdot (\Sigma(x, t) \nabla)+\mu(x, t)\cdot \nabla + \kappa^2(x, t)\right]^{\alpha/2}u(x,t) = w(x,t)
\end{equation}
where $\mu, \Sigma, \kappa$ are functions of $x, t$, and $w(x, t)$ is a GeRF driven by Equ (\ref{SPDE}).
